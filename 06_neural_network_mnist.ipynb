{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantosCristiano/artificial-intelligence-python/blob/main/06_neural_network_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJ5kYRgT5Im"
      },
      "source": [
        "# Aula 20 - Tensor Flow - Redes Neurais - MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWpFfw10Gq1J"
      },
      "source": [
        "# TensorFlow 2.0\n",
        "Este notebook é baseado no Tensorflow no notebook de **Martin Gorner** e foi modificado para ser executado no TensorFlow 2.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCr5-FrwcTt"
      },
      "source": [
        "## 1. Introdução\n",
        "Nesta prática, você aprenderá como construir e treinar uma rede neural que reconhece dígitos manuscritos. <br />Ao longo do caminho, conforme você aprimora sua rede neural para atingir 99% de precisão, você também descobrirá as ferramentas comerciais que os profissionais de aprendizado profundo usam para treinar seus modelos com eficiência.\n",
        "\n",
        "Este codelab usa o conjunto de dados MNIST, uma coleção de 60.000 dígitos rotulados que manteve gerações de PhDs ocupadas por quase duas décadas.<br /> Você resolverá o problema com menos de 100 linhas de código Python / TensorFlow.\n",
        "\n",
        "O que você aprenderá:\n",
        "* O que é uma rede neural e como treiná-la\n",
        "* Como construir uma rede neural básica de 1 camada usando TensorFlow\n",
        "* Como adicionar mais camadas\n",
        "* Dicas e truques de treinamento: overfitting, evasão, diminuição da taxa de aprendizagem ...\n",
        "* Como solucionar problemas de redes neurais profundas\n",
        "* Como construir redes convolucionais\n",
        "\n",
        "O que você precisará:\n",
        "* Python 2 ou 3 (Python 3 recomendado)\n",
        "* TensorFlow\n",
        "\n",
        "### Executando na GPU\n",
        "Para esta prática, você precisará usar uma GPU para acelerar o treinamento.<br /> Para fazer isso, vá ao menu \"Runtime\" do Colab, selecione \"Alterar tipo de tempo de execução\" e, no menu pop-up, escolha \"GPU\" na caixa \"Acelelador de hardware\". Isso é tudo que você precisa fazer, Colab e Tensorflow cuidarão do resto!\n",
        "\n",
        "### Requisitos de instalação\n",
        "Primeiro, precisamos instalar o TensorFlow 2.0 e fazer o download do ngrock (o ngrock só é usado para executar o TensorBoard no Google Colab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW0h7zV9LY13"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PadTIqHI81Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58074bd3-aac2-4bd6-90ec-7182b50e1d5c"
      },
      "source": [
        "#@title Dependências e importações (EXECUTE-ME!) { display-mode: \"form\" }\n",
        "\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 03:01:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  12.7MB/s    in 1.0s    \n",
            "\n",
            "2021-09-01 03:01:51 (12.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDE95JgoyMQ8"
      },
      "source": [
        "### TensorBoard\n",
        "TensorBoard é uma ferramenta usada para monitorar o treinamento e investigar o modelo e os resultados.\n",
        "\n",
        "Execute a próxima célula para iniciar o TensorBoard em segundo plano. Em seguida, clique no link para acessar o TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5d8bgEhyXl0"
      },
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIayMTsMyQJg"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egle5fIozS-z",
        "outputId": "3046ceec-2c49-40f3-8d0a-4a2f4cfcc0cf"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://790c-34-90-61-234.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuYQMd3ez5lr"
      },
      "source": [
        "## 2. Os dados\n",
        "Nesta prática, usamos o conjunto de dados MNIST que consiste em 70.000 imagens de dígitos entre 0 e 9, manuscritos, em escala de cinza e seus rótulos.<br />\n",
        "A ideia é treinar um classificador para identificar o valor da classe (que é o dígito manuscrito) dado a imagem. <br />Treinaremos e ajustaremos um modelo nas 60.000 imagens de treinamento e em seguida, avaliaremos como ele classifica as 10.000 imagens de teste que o modelo não viu durante o treinamento.<br /> Esta tarefa é um exemplo de problema de aprendizagem supervisionada, em que recebemos informações e rótulos (metas) para aprender. <br />Isso contrasta com o aprendizado não supervisionado, em que temos apenas entradas para aprender padrões ou aprendizado por reforço, em que um agente aprende como maximizar um sinal de recompensa por meio da interação com seu ambiente.\n",
        "\n",
        "### Divisão de treinamento / validação / teste\n",
        "Quando construímos modelos de aprendizado de máquina, o objetivo é construir um modelo que terá um bom desempenho em dados futuros que ainda não viu.<br /> Dizemos que queremos que nossos modelos sejam capazes de generalizar bem a partir de quaisquer dados de treinamento que possamos coletar e tivermos disponíveis, para quaisquer dados aos quais iremos aplicá-los no futuro.<br /> Para fazer isso, dividimos todos os dados que temos disponíveis em um conjunto de treinamento, um conjunto de validação e um conjunto de teste.<br /> A ideia é treinar nosso modelo e usar o desempenho no conjunto de validação para fazer quaisquer ajustes no modelo e seus hiperparâmetros, e então relatamos a precisão final no conjunto de teste.<br />O conjunto de teste (com o qual o modelo nunca treinou), portanto, atua como uma prova, simulando os dados futuros que terá que prever.\n",
        "\n",
        "### Carregar o conjunto de dados\n",
        "Execute a próxima célula para baixar o conjunto de dados mnist e preparar os conjuntos de treinamento e teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIYprAwjwdI"
      },
      "source": [
        "### Import do tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66l2lTNx1jWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37dd680-c5c3-45d1-a0e4-aaf75c0ec01e"
      },
      "source": [
        "# Carrega o conjunto de dados mnist\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Divide o conjunto de dados em conjuntos de treinamento / teste\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLCVlYihGdP"
      },
      "source": [
        "<b>x_train</b>, <b>y_train</b>, <b>x_test</b> e <b>y_test</b> representam o seguinte\n",
        "\n",
        "<b>x_train</b> é **60.000** imagens de treinamento como imagens de **28 x 28** pixels com cada pixel tendo um valor inteiro de **0-255**\n",
        "\n",
        "<b>y_train</b> é **60.000** rótulos de treinamento, um para cada uma das imagens de treinamento com cada rótulo tendo um valor inteiro de **0-9** correspondendo aos dígitos de **0-9** que cada uma das imagens representa.\n",
        "\n",
        "<b>x_test</b> é **10.000** imagens de teste como imagens de **28 x 28** pixels com cada pixel tendo um valor inteiro de **0-255**\n",
        "\n",
        "<b>y_test</b> é **10.000** rótulos de teste, um para cada uma das imagens de teste com cada rótulo tendo um valor inteiro de **0-9** correspondendo aos dígitos de **0-9** que cada uma das imagens representa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWFZt9ojhUEy",
        "outputId": "45d307d3-05de-4cda-94e1-5daedd5f83fa"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiTEVzRyVj10",
        "outputId": "ba6cc296-ffdd-419d-e620-a48e7c9dad16"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esBeSTrDhZDD",
        "outputId": "80b0d6ae-8d6b-4d8a-a042-41b8584c303e"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGhUap36Svl3",
        "outputId": "d311c755-a47f-4c4b-aecd-114d747def21"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UCOZwj422hT"
      },
      "source": [
        "### Pega a imagem de **índice 2**, isto é, a **terceira** imagem do **x_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2kM7oQybDzz"
      },
      "source": [
        "single_image = x_train[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf33_z5tWkqI"
      },
      "source": [
        "## Verifica valores **min** e **max** dos pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts9J9tTzbI77",
        "outputId": "53ed11df-ee8b-402b-a46d-f19f74b62bf2"
      },
      "source": [
        "single_image.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C22FyjhTbJex",
        "outputId": "d8d1add9-f446-4f20-ab4d-aec5b3d80cfe"
      },
      "source": [
        "single_image.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abs0AcF6K0j2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "h1vB57OoS2hs",
        "outputId": "2da166ea-70ab-47ad-fb12-52020f95fbfd"
      },
      "source": [
        "plt.imshow(x_train[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a91f7b4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FsZaa4ABaISQ",
        "outputId": "1f47c992-6ba8-4e0b-8f9b-7119e5c8123c"
      },
      "source": [
        "plt.imshow(x_train[2], cmap='gist_gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a91a5e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqOZwGe6XM5K"
      },
      "source": [
        "### Agora, precisamos normalizar nossos pixels dividindo o valor por 255, a fim de ter um intervalo normalizado para nossa rede"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbGameaeabr3"
      },
      "source": [
        "Normalizando os valores das imagens de [0, 255] para [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FpS9odqWJcZ"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFcMybGsmgrj"
      },
      "source": [
        "single_image_02 = x_train[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I4j2vC0mKeg",
        "outputId": "82f1afe7-fbe3-4020-905a-3d77e57b68f1"
      },
      "source": [
        "single_image_02.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIX-j_G3mLAS",
        "outputId": "ab93ffa1-9a11-4dd2-f56c-aa91fa6ad956"
      },
      "source": [
        "single_image_02.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkrC7cyoDFRc"
      },
      "source": [
        "## 3. Teoria: uma rede neural de 1 camada\n",
        "\n",
        "![image_1](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/1.png?raw=true)\n",
        "\n",
        "Os dígitos manuscritos no conjunto de dados **MNIST** são imagens em escala de cinza de **28 x 28** pixels.<br />A abordagem mais simples para classificá-los é usar **28 x 28 = 784** pixels como entradas para uma rede neural de **1 camada**.\n",
        "\n",
        "![](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/2.png?raw=true)\n",
        "\n",
        "Cada \"neurônio\" em uma rede neural faz uma soma ponderada de todas as suas entradas, adiciona uma constante chamada \"viés\", e em seguida, alimenta o resultado por meio de alguma função de ativação não linear.\n",
        "\n",
        "Aqui, projetamos uma rede neural de 1 camada com 10 neurônios de saída, pois queremos classificar os dígitos em 10 classes (0 a 9).\n",
        "\n",
        "Para um problema de classificação, uma função de ativação que funciona bem é a softmax. A aplicação da softmax em um vetor é feita tomando o exponencial de cada elemento e, em seguida, normalizando o vetor (usando qualquer norma, por exemplo, o comprimento euclidiano comum do vetor).\n",
        "\n",
        "![alt text](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/3.png?raw=true)\n",
        "\n",
        "***Por que a \"softmax\" é chamada de softmax? <br />O exponencial é uma função que aumenta abruptamente. <br />Isso aumentará as diferenças entre os elementos do vetor. <br />Também produz grandes valores rapidamente. <br />Então, conforme você normaliza o vetor, o maior elemento, que domina a norma será normalizado para um valor próximo a 1, enquanto todos os outros elementos serão divididos por um grande valor e normalizados para algo próximo a 0. O vetor resultante mostra claramente qual era o seu maior elemento, o \"max\", mas retém a ordem relativa original de seus valores, daí o \"soft\".***\n",
        "\n",
        "Vamos agora resumir o comportamento dessa única camada de neurônios em uma fórmula simples usando uma multiplicação de matriz.<br /> Vamos fazer isso diretamente para um \"minilote\" de 100 imagens como entrada, produzindo 100 previsões (vetores de 10 elementos) como saída.\n",
        "\n",
        "![alt text](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/4.png?raw=true)\n",
        "\n",
        "Usando a primeira coluna de pesos na matriz de pesos W, calculamos a soma ponderada de todos os pixels da primeira imagem.<br /> Essa soma corresponde ao primeiro neurônio.<br /> Usando a segunda coluna de pesos, fazemos o mesmo para o segundo neurônio e assim por diante até o 10º neurônio. <br />Podemos então repetir a operação para as 99 imagens restantes. <br />Se chamarmos X de matriz que contém nossas 100 imagens, todas as somas ponderadas de nossos 10 neurônios, calculadas em 100 imagens, serão simplesmente X.W (multiplicação da matriz).\n",
        "\n",
        "Cada neurônio deve agora adicionar seu viés (uma constante).<br /> Como temos 10 neurônios, temos 10 constantes de **bias**, ou em português, **viés**. <br />Chamaremos esse vetor de 10 valores de **b**. <br />Deve ser adicionado a cada linha da matriz calculada anteriormente. <br />Usando um pouco da mágica chamada \"Broadcasting\", escreveremos isso com um simples sinal de mais.\n",
        "\n",
        "***\"Broadcasting é um truque padrão usado em Python e numpy. <br />Ele amplia como as operações normais funcionam em matrizes com dimensões incompatíveis.<br /> \"Broadcasting add\" significa que se você está adicionando duas matrizes, mas não pode porque suas dimensões não são compatíveis, ele tenta replicar a matriz menor tanto quanto necessário para fazer funcionar.\"***\n",
        "\n",
        "Finalmente aplicamos a função de ativação ***softmax*** e obtemos a fórmula que descreve uma rede neural de 1 camada, aplicada a 100 imagens:\n",
        "\n",
        "![alt text](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/5.png?raw=true)\n",
        "\n",
        "***O que é um \"tensor\"?\n",
        "Um \"tensor\" é como uma matriz, mas com um número arbitrário de dimensões.<br /> Um tensor unidimensional é um vetor. Um tensor de 2 dimensões é uma matriz. E então você pode ter tensores com 3, 4, 5 ou mais dimensões.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afr-117jF2tQ"
      },
      "source": [
        "## 4. Gradiente descendente\n",
        "Agora que nossa rede neural produz previsões a partir de imagens de entrada, precisamos medir o quão boas elas são, ou seja, a distância entre o que a rede nos diz e o que sabemos ser a verdade. Lembre-se de que temos rótulos verdadeiros para todas as imagens neste conjunto de dados.\n",
        "\n",
        "Qualquer distância funcionaria, a distância euclidiana comum é boa, mas para problemas de classificação uma distância, chamada de \"entropia cruzada\", é mais eficiente.\n",
        "\n",
        "![texto alternativo](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/6.png?raw=true)\n",
        "\n",
        "***A codificação \"one-hot\" significa que você representa o rótulo \"6\" usando um vetor de 10 valores, todos zeros, mas o 6º valor é 1. É útil aqui porque o formato é muito semelhante ao nosso sistema da rede neural que emite previsões, também em um vetor de 10 valores.***\n",
        "\n",
        "\"Treinar\" a rede neural, na verdade, significa usar imagens e rótulos de treinamento para ajustar pesos e vieses de modo a minimizar a função de perda de entropia cruzada. É assim que funciona.\n",
        "\n",
        "A entropia cruzada é função de pesos, vieses, pixels da imagem de treinamento e seu rótulo conhecido.\n",
        "\n",
        "Se calcularmos as derivadas parciais da entropia cruzada relativamente a todos os pesos e todos os vieses, obtemos um \"gradiente\", calculado para uma dada imagem, rótulo e valor presente dos pesos e vieses. Lembre-se de que temos 7.850 pesos e vieses, portanto, calcular o gradiente parece muito trabalhoso. Felizmente, o TensorFlow fará isso por nós.\n",
        "\n",
        "A propriedade matemática de um gradiente é apontar para \"cima\". Visto que queremos ir onde a entropia cruzada é baixa, vamos na direção oposta. Atualizamos pesos e tendências (**bias**) por uma fração do gradiente e fazemos a mesma coisa novamente usando o próximo lote de imagens de treinamento. Esperançosamente, isso nos levará ao fundo do poço, onde a entropia cruzada é mínima.\n",
        "\n",
        "![alt text](https://github.com/YoussefBenDhieb/tensorflow-without-a-phd/blob/master/colabs/assets/7.png?raw=true)\n",
        "\n",
        "Nesta figura, a entropia cruzada é representada como uma função de 2 pesos. Na realidade, existem muitos mais. O algoritmo de descida gradiente segue o caminho da descida mais íngreme até um mínimo local. As imagens de treinamento também são alteradas a cada iteração para que possamos convergir para um mínimo local que funcione para todas as imagens.\n",
        "\n",
        "***\"Taxa de aprendizagem\": você não pode atualizar seus pesos e vieses por todo o comprimento do gradiente em cada iteração. Seria como tentar chegar ao fundo de um vale usando botas de sete léguas. Você estaria pulando de um lado do vale para o outro. Para chegar ao fundo, você precisa fazer etapas menores, ou seja, usar apenas uma fração do gradiente, normalmente na região 1/1000. Chamamos essa fração de \"taxa de aprendizado\".***\n",
        "\n",
        "Para resumir, esta é a aparência do loop de treinamento:\n",
        "`` `\n",
        "Dígitos e rótulos de treinamento => função de perda => gradiente (derivadas parciais) => descida mais íngreme => atualizar pesos e tendências => repetir com o próximo minilote de imagens de treinamento e rótulos\n",
        "`` `\n",
        "<br />\n",
        "***Por que trabalhar com \"minilotes\" de 100 imagens e rótulos?***\n",
        "\n",
        "***Você pode definitivamente calcular seu gradiente em apenas uma imagem de exemplo e atualizar os pesos e vieses imediatamente (é chamado de \"descida gradiente estocástica\" na literatura científica). Fazer isso em 100 exemplos fornece um gradiente que representa melhor as restrições impostas por diferentes imagens de exemplo e, portanto, provavelmente convergirá para a solução mais rapidamente. O tamanho do minilote é um parâmetro ajustável. Há outro motivo, mais técnico: trabalhar com lotes também significa trabalhar com matrizes maiores e geralmente são mais fáceis de otimizar em GPUs.***\n",
        "\n",
        "## 5. Laboratório: vamos pular para o código\n",
        "\n",
        "### Defina o modelo\n",
        "Nesta seção, construiremos um classificador. Um **classificador** é uma função que pega as características de um objeto (ou \"recursos\") como entradas e produz uma previsão da classe (ou grupo) a que o objeto pertence. Ele pode fazer uma única previsão para cada entrada ou pode produzir alguma pontuação (por exemplo, uma probabilidade) para cada uma das classes possíveis. Especificamente, construiremos um classificador que recebe (um lote de) 28 x 28 imagens MNIST, como vimos acima, e gera previsões sobre a qual classe a imagem pertence.\n",
        "\n",
        "Para cada (lote de) imagens de entrada, usaremos uma **rede neural feed-forward** para calcular pontuações não normalizadas (também conhecidas como **logits**) para cada uma das 10 classes possíveis às quais a imagem pode pertencer. Podemos então **classificar** a imagem como pertencente à classe que recebe a pontuação mais alta, ou podemos quantificar a \"confiança\" do modelo sobre as classificações, convertendo as pontuações em uma distribuição de probabilidade.\n",
        "\n",
        "Uma rede neural feed-forward que consiste em $N$ camadas, aplicadas a um vetor de entrada $\\mathbf{x}$ pode ser definido como:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbf{f_0} = \\mathbf{x} \\\\\n",
        "\\mathbf{f_i} = \\sigma_i(\\mathbf{W_if_{i-1}} + \\mathbf{b_i}) \\ \\ \\ i \\in [1, N]\n",
        "\\end{equation}\n",
        "\n",
        "Cada camada tem um número particular, $m_i$, de neurônios. Os parâmetros de uma camada consistem em uma matriz $\\mathbf{W_i} \\in \\mathbb{R}^{m_i \\times m_{i-1}}$ e vetor de bias $\\mathbf{b_i} \\in \\mathbb{R}^{m_i}$. Cada camada também tem uma função de ativação não linear $\\sigma_i$.\n",
        "\n",
        "**PERGUNTA**: Por que você acha que as funções de ativação precisam ser **não lineares**? O que aconteceria se elas fossem **lineares**? **DICA**: Se você estiver travado, considere o caso mais simples de uma ativação de identidade (que essencialmente não faz nada) e ignore os preconceitos.\n",
        "\n",
        "### Funções de ativação\n",
        "\n",
        "As funções de ativação são um ingrediente central nas redes neurais profundas. Na verdade, são elas que nos permitem fazer uso de várias camadas em uma rede neural. Existem várias funções de ativação diferentes, cada uma das quais mais ou menos útil em diferentes circunstâncias. As quatro funções de ativação que você provavelmente encontrará são, sem dúvida,[ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU), [Tanh](https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh), [Sigmoid](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid), e [Softmax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax)..\n",
        "\n",
        "ReLU, nos últimos anos, tornou-se a escolha padrão para uso em MLPs e Redes Neurais Convolucionais (CNNs). ReLU tem duas vantagens sobre Tanh e Sigmoid: é computacionalmente muito mais eficiente e nos permite usar redes mais profundas porque não sofre de [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). Como resultado de seu sucesso, uma série de variantes ReLU, como [LeakyRelu](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU) e [PReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/PReLU), foram desenvolvidos.\n",
        "\n",
        "As ativações Sigmoid e Softmax são frequentemente encontradas após a última camada em redes de classificação binária e multiclasse, respectivamente, pois transformam as saídas da rede de forma que possamos interpretá-las como probabilidades de classe.\n",
        "\n",
        "Tanh e Sigmoid são encontradas em redes neurais recorrentes LSTM e GRU, sobre as quais aprenderemos mais nos próximos episódios. Elas também são úteis em MLPs e CNNs, onde queremos que a saída seja limitada entre -1 e 1 (Tanh) ou 0 e 1 (Sigmóide).\n",
        "\n",
        "Leia mais sobre as funções de ativação [aqui](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6).\n",
        "\n",
        "### Crie uma rede neural de 1 camada\n",
        "Configuramos a parte da rede neural feed-forward de nosso classificador usando a [Keras Layers API](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Esta API consiste em vários blocos de construção reutilizáveis ​​que nos permitem definir muitas arquiteturas de rede neural diferentes (semelhante a como definimos um pipeline de dados anteriormente!).\n",
        "\n",
        "Aqui usamos o componente [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) que nos permite agrupar uma sequência de camadas. Um ponto importante a observar aqui é que estamos **configurando** nossa arquitetura de rede neural como um pipeline. Podemos pensar na variável `` `model`` resultante como uma **função** que pega um lote de imagens como entradas e produz um lote de logits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x77S35jLOpZ"
      },
      "source": [
        "# Define o modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "# achata as imagens em uma única linha de pixels, um vetor\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten_input'),\n",
        "# aplica softmax como uma função de ativação\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='logits')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkbutRx0Lawr"
      },
      "source": [
        "O resumo a seguir mostra quantos parâmetros cada camada é composta (o número de entradas na matriz de pesos e vetores de bias). Observe que um valor de ```None``` em uma dimensão específica, significa que a forma se adaptará dinamicamente com base na forma das entradas. Em particular, a forma de saída do ```flatten_input``` será $[N, 784]$ quando o lote de entradas passado para o modelo tem a forma $[N, 28, 28]$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_ESVVFNL0-t",
        "outputId": "0ea16aa3-6d9c-43cd-abc5-d0e8ac901511"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_input (Flatten)      (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YK8IO0gOYQy"
      },
      "source": [
        "### Defina a perda\n",
        "Como fizemos na prática anterior, precisamos especificar uma função de perda para nosso classificador. Isso nos diz o quão boas são as previsões do nosso modelo em comparação com os rótulos reais (os alvos), com uma perda menor significando melhores previsões. A função de perda padrão para usar com um **classificador multiclasse** é a **perda de entropia cruzada** também conhecida como \"probabilidade de log negativo\". Suponha que temos um problema de classificação com classes $C$. Um classificador é treinado para prever uma distribuição de probabilidade $p(y|X_i)$ para cada entrada $X_i$ de um lote de $N$ exemplos. O vetor $p(y|X_i)$ é $C$ dimensional, soma um, e usamos $p(y|X_i)_c$ para denotar o $c$ th componente de $p(y|X_i)$. A verdadeira classe por exemplo $i$ no lote é $y_i$ e definimos a função indicadora $\\mathbb{1}[y_i = c]$ como 1 sempre que $y_i=c$ e $0$ caso contrário. Este classificador tem uma perda de entropia cruzada de\n",
        "\n",
        "$- \\frac{1}{N}\\sum_{i=1}^N \\sum_{c=1}^C log( p(y|X_i)_c) \\mathbb{1}[y_i=c]$\n",
        "\n",
        "**NOTA**: O indicador é um para o verdadeiro rótulo da classe e zero para todas as outras. Portanto, nessa soma, o indicador apenas \"levanta\" os valores $log(p(y|X_i))$ para todas as classes verdadeiras. Portanto, a expressão acima é minimizada (observe o negativo na frente) quando o modelo coloca toda a sua massa de probabilidade nos rótulos verdadeiros para todos os exemplos. Lembre-se de que log(1) = 0, portanto, quanto mais próximas de um todas as probabilidades de $y_i = c$, menor será a perda e melhor será o desempenho do modelo.\n",
        "\n",
        "**PERGUNTA**:\n",
        "* Por que você acha que esta é uma função de perda *boa*?\n",
        "* Você consegue pensar em algum problema potencial com essa função de perda?\n",
        "\n",
        "Felizmente, não precisamos escrever essa função, pois o Tensorflow fornece uma versão chamada\n",
        "\n",
        "```tf.nn.sparse_softmax_cross_entropy_with_logits```.\n",
        "\n",
        "**NOTA**: Esta função realmente calcula a perda de entropia cruzada diretamente dos logits não normalizados, ao invés da distribuição de probabilidade para estabilidade numérica.\n",
        "\n",
        "A propósito, para dados de treinamento em que os próprios rótulos são distribuições em vez de valores exatos, essa definição de entropia cruzada ainda funciona, onde a função de indicador é substituída pela probabilidade correspondente de cada classe para aquele exemplo. Isso pode ser importante quando não temos certeza se os dados de treinamento foram rotulados corretamente ou quando os dados foram rotulados por um humano que deu sua resposta junto com um certo grau de confiança de que a resposta estava correta.\n",
        "\n",
        "### Treine o modelo\n",
        "Agora que temos nossos dados, pipeline de processamento de dados, nossa arquitetura de rede neural e a perda correspondente que queremos minimizar, precisamos **treinar** o modelo usando descida gradiente estocástica em lote. Fazemos isso em várias **épocas**, que é uma única iteração em todo o conjunto de dados de treinamento. Resumidamente, em cada época, fazemos um loop em todos os lotes de imagens e rótulos e, para cada lote, executamos as seguintes etapas:\n",
        "* Obtenha as **previsões** do modelo no lote atual de imagens\n",
        "* Calcule os valores de **perda média** em todo o lote, informando-nos quão boas são essas previsões / quão próximas estão dos alvos verdadeiros.\n",
        "* Calcule o **gradiente da perda média** (ou o gradiente médio das perdas no lote) com relação a cada um dos parâmetros do modelo: Isso nos diz a direção para mover no \"espaço de parâmetros\" para diminuir o valor da perda\n",
        "* **Ajuste os parâmetros** dando um pequeno passo na direção de cada componente do gradiente (onde a taxa de aprendizado controla o tamanho do passo)\n",
        "\n",
        "Durante o treinamento, também rastreamos algumas métricas, como a perda e a precisão, para ver como o classificador está se saindo. Observe que a célula abaixo pode levar alguns minutos para ser executada!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n0WIQmAkdMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b638b2f-b04e-4f02-937e-19f14407e94f"
      },
      "source": [
        "def train_model():\n",
        "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.005),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=1)\n",
        "\n",
        "  model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            batch_size=100,\n",
        "            epochs=300,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[tensorboard_callback])\n",
        "\n",
        "train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "600/600 [==============================] - 2s 2ms/step - loss: 1.4880 - accuracy: 0.6318 - val_loss: 1.0013 - val_accuracy: 0.8062\n",
            "Epoch 2/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.8656 - accuracy: 0.8187 - val_loss: 0.7299 - val_accuracy: 0.8444\n",
            "Epoch 3/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.6925 - accuracy: 0.8443 - val_loss: 0.6177 - val_accuracy: 0.8609\n",
            "Epoch 4/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.6086 - accuracy: 0.8573 - val_loss: 0.5553 - val_accuracy: 0.8705\n",
            "Epoch 5/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.5575 - accuracy: 0.8649 - val_loss: 0.5146 - val_accuracy: 0.8762\n",
            "Epoch 6/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.5227 - accuracy: 0.8708 - val_loss: 0.4855 - val_accuracy: 0.8812\n",
            "Epoch 7/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4971 - accuracy: 0.8747 - val_loss: 0.4638 - val_accuracy: 0.8836\n",
            "Epoch 8/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.8781 - val_loss: 0.4467 - val_accuracy: 0.8860\n",
            "Epoch 9/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4614 - accuracy: 0.8809 - val_loss: 0.4326 - val_accuracy: 0.8886\n",
            "Epoch 10/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4483 - accuracy: 0.8830 - val_loss: 0.4210 - val_accuracy: 0.8905\n",
            "Epoch 11/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4373 - accuracy: 0.8848 - val_loss: 0.4112 - val_accuracy: 0.8929\n",
            "Epoch 12/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4279 - accuracy: 0.8870 - val_loss: 0.4026 - val_accuracy: 0.8942\n",
            "Epoch 13/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.8882 - val_loss: 0.3955 - val_accuracy: 0.8956\n",
            "Epoch 14/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4125 - accuracy: 0.8896 - val_loss: 0.3890 - val_accuracy: 0.8972\n",
            "Epoch 15/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.4060 - accuracy: 0.8911 - val_loss: 0.3831 - val_accuracy: 0.8987\n",
            "Epoch 16/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8924 - val_loss: 0.3779 - val_accuracy: 0.8999\n",
            "Epoch 17/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8935 - val_loss: 0.3731 - val_accuracy: 0.9008\n",
            "Epoch 18/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3904 - accuracy: 0.8946 - val_loss: 0.3690 - val_accuracy: 0.9015\n",
            "Epoch 19/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8954 - val_loss: 0.3649 - val_accuracy: 0.9021\n",
            "Epoch 20/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3822 - accuracy: 0.8961 - val_loss: 0.3615 - val_accuracy: 0.9029\n",
            "Epoch 21/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3785 - accuracy: 0.8969 - val_loss: 0.3582 - val_accuracy: 0.9038\n",
            "Epoch 22/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3751 - accuracy: 0.8978 - val_loss: 0.3552 - val_accuracy: 0.9048\n",
            "Epoch 23/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3720 - accuracy: 0.8982 - val_loss: 0.3524 - val_accuracy: 0.9050\n",
            "Epoch 24/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3690 - accuracy: 0.8991 - val_loss: 0.3496 - val_accuracy: 0.9058\n",
            "Epoch 25/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3662 - accuracy: 0.8996 - val_loss: 0.3472 - val_accuracy: 0.9060\n",
            "Epoch 26/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3636 - accuracy: 0.9003 - val_loss: 0.3449 - val_accuracy: 0.9068\n",
            "Epoch 27/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.9009 - val_loss: 0.3428 - val_accuracy: 0.9070\n",
            "Epoch 28/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3589 - accuracy: 0.9014 - val_loss: 0.3407 - val_accuracy: 0.9078\n",
            "Epoch 29/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.9021 - val_loss: 0.3388 - val_accuracy: 0.9082\n",
            "Epoch 30/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3547 - accuracy: 0.9022 - val_loss: 0.3371 - val_accuracy: 0.9093\n",
            "Epoch 31/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.9030 - val_loss: 0.3353 - val_accuracy: 0.9094\n",
            "Epoch 32/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3508 - accuracy: 0.9035 - val_loss: 0.3337 - val_accuracy: 0.9094\n",
            "Epoch 33/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3490 - accuracy: 0.9036 - val_loss: 0.3321 - val_accuracy: 0.9094\n",
            "Epoch 34/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3473 - accuracy: 0.9042 - val_loss: 0.3305 - val_accuracy: 0.9100\n",
            "Epoch 35/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.9048 - val_loss: 0.3291 - val_accuracy: 0.9104\n",
            "Epoch 36/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.9051 - val_loss: 0.3277 - val_accuracy: 0.9106\n",
            "Epoch 37/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.9057 - val_loss: 0.3265 - val_accuracy: 0.9112\n",
            "Epoch 38/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3412 - accuracy: 0.9060 - val_loss: 0.3253 - val_accuracy: 0.9113\n",
            "Epoch 39/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.9063 - val_loss: 0.3241 - val_accuracy: 0.9119\n",
            "Epoch 40/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3385 - accuracy: 0.9067 - val_loss: 0.3229 - val_accuracy: 0.9117\n",
            "Epoch 41/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3373 - accuracy: 0.9071 - val_loss: 0.3218 - val_accuracy: 0.9120\n",
            "Epoch 42/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3360 - accuracy: 0.9074 - val_loss: 0.3209 - val_accuracy: 0.9121\n",
            "Epoch 43/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.9076 - val_loss: 0.3199 - val_accuracy: 0.9130\n",
            "Epoch 44/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3337 - accuracy: 0.9079 - val_loss: 0.3190 - val_accuracy: 0.9131\n",
            "Epoch 45/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9084 - val_loss: 0.3180 - val_accuracy: 0.9130\n",
            "Epoch 46/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3315 - accuracy: 0.9085 - val_loss: 0.3171 - val_accuracy: 0.9132\n",
            "Epoch 47/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.9088 - val_loss: 0.3162 - val_accuracy: 0.9133\n",
            "Epoch 48/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3295 - accuracy: 0.9093 - val_loss: 0.3153 - val_accuracy: 0.9134\n",
            "Epoch 49/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.9092 - val_loss: 0.3144 - val_accuracy: 0.9135\n",
            "Epoch 50/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3276 - accuracy: 0.9096 - val_loss: 0.3136 - val_accuracy: 0.9138\n",
            "Epoch 51/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.9100 - val_loss: 0.3128 - val_accuracy: 0.9136\n",
            "Epoch 52/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3258 - accuracy: 0.9102 - val_loss: 0.3121 - val_accuracy: 0.9137\n",
            "Epoch 53/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3249 - accuracy: 0.9103 - val_loss: 0.3114 - val_accuracy: 0.9144\n",
            "Epoch 54/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3241 - accuracy: 0.9107 - val_loss: 0.3107 - val_accuracy: 0.9147\n",
            "Epoch 55/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.9110 - val_loss: 0.3101 - val_accuracy: 0.9144\n",
            "Epoch 56/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.9112 - val_loss: 0.3094 - val_accuracy: 0.9148\n",
            "Epoch 57/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.9111 - val_loss: 0.3088 - val_accuracy: 0.9151\n",
            "Epoch 58/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3209 - accuracy: 0.9113 - val_loss: 0.3081 - val_accuracy: 0.9157\n",
            "Epoch 59/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3202 - accuracy: 0.9118 - val_loss: 0.3075 - val_accuracy: 0.9157\n",
            "Epoch 60/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3195 - accuracy: 0.9117 - val_loss: 0.3072 - val_accuracy: 0.9158\n",
            "Epoch 61/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3188 - accuracy: 0.9122 - val_loss: 0.3063 - val_accuracy: 0.9161\n",
            "Epoch 62/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3181 - accuracy: 0.9120 - val_loss: 0.3060 - val_accuracy: 0.9161\n",
            "Epoch 63/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3174 - accuracy: 0.9124 - val_loss: 0.3052 - val_accuracy: 0.9166\n",
            "Epoch 64/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3168 - accuracy: 0.9126 - val_loss: 0.3047 - val_accuracy: 0.9168\n",
            "Epoch 65/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3161 - accuracy: 0.9128 - val_loss: 0.3043 - val_accuracy: 0.9165\n",
            "Epoch 66/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.9128 - val_loss: 0.3039 - val_accuracy: 0.9164\n",
            "Epoch 67/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3149 - accuracy: 0.9133 - val_loss: 0.3031 - val_accuracy: 0.9165\n",
            "Epoch 68/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3143 - accuracy: 0.9134 - val_loss: 0.3028 - val_accuracy: 0.9172\n",
            "Epoch 69/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.9132 - val_loss: 0.3025 - val_accuracy: 0.9170\n",
            "Epoch 70/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3132 - accuracy: 0.9133 - val_loss: 0.3020 - val_accuracy: 0.9172\n",
            "Epoch 71/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3126 - accuracy: 0.9136 - val_loss: 0.3016 - val_accuracy: 0.9168\n",
            "Epoch 72/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3120 - accuracy: 0.9138 - val_loss: 0.3010 - val_accuracy: 0.9168\n",
            "Epoch 73/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3115 - accuracy: 0.9136 - val_loss: 0.3006 - val_accuracy: 0.9173\n",
            "Epoch 74/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3110 - accuracy: 0.9140 - val_loss: 0.3001 - val_accuracy: 0.9166\n",
            "Epoch 75/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.9139 - val_loss: 0.2998 - val_accuracy: 0.9169\n",
            "Epoch 76/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3100 - accuracy: 0.9142 - val_loss: 0.2994 - val_accuracy: 0.9167\n",
            "Epoch 77/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3095 - accuracy: 0.9141 - val_loss: 0.2990 - val_accuracy: 0.9170\n",
            "Epoch 78/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3090 - accuracy: 0.9145 - val_loss: 0.2985 - val_accuracy: 0.9167\n",
            "Epoch 79/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3085 - accuracy: 0.9146 - val_loss: 0.2983 - val_accuracy: 0.9175\n",
            "Epoch 80/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3080 - accuracy: 0.9147 - val_loss: 0.2980 - val_accuracy: 0.9169\n",
            "Epoch 81/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3076 - accuracy: 0.9148 - val_loss: 0.2976 - val_accuracy: 0.9172\n",
            "Epoch 82/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3071 - accuracy: 0.9153 - val_loss: 0.2972 - val_accuracy: 0.9173\n",
            "Epoch 83/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3067 - accuracy: 0.9154 - val_loss: 0.2968 - val_accuracy: 0.9171\n",
            "Epoch 84/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3063 - accuracy: 0.9151 - val_loss: 0.2965 - val_accuracy: 0.9173\n",
            "Epoch 85/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.9154 - val_loss: 0.2961 - val_accuracy: 0.9172\n",
            "Epoch 86/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.9154 - val_loss: 0.2957 - val_accuracy: 0.9173\n",
            "Epoch 87/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3050 - accuracy: 0.9156 - val_loss: 0.2954 - val_accuracy: 0.9175\n",
            "Epoch 88/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3046 - accuracy: 0.9157 - val_loss: 0.2953 - val_accuracy: 0.9173\n",
            "Epoch 89/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3042 - accuracy: 0.9158 - val_loss: 0.2949 - val_accuracy: 0.9175\n",
            "Epoch 90/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3038 - accuracy: 0.9158 - val_loss: 0.2947 - val_accuracy: 0.9175\n",
            "Epoch 91/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3034 - accuracy: 0.9160 - val_loss: 0.2945 - val_accuracy: 0.9178\n",
            "Epoch 92/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3030 - accuracy: 0.9157 - val_loss: 0.2941 - val_accuracy: 0.9174\n",
            "Epoch 93/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3027 - accuracy: 0.9162 - val_loss: 0.2937 - val_accuracy: 0.9177\n",
            "Epoch 94/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3023 - accuracy: 0.9161 - val_loss: 0.2934 - val_accuracy: 0.9175\n",
            "Epoch 95/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3019 - accuracy: 0.9161 - val_loss: 0.2932 - val_accuracy: 0.9177\n",
            "Epoch 96/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3016 - accuracy: 0.9165 - val_loss: 0.2930 - val_accuracy: 0.9175\n",
            "Epoch 97/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3012 - accuracy: 0.9164 - val_loss: 0.2928 - val_accuracy: 0.9184\n",
            "Epoch 98/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.9167 - val_loss: 0.2924 - val_accuracy: 0.9175\n",
            "Epoch 99/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3005 - accuracy: 0.9166 - val_loss: 0.2922 - val_accuracy: 0.9172\n",
            "Epoch 100/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.3002 - accuracy: 0.9170 - val_loss: 0.2920 - val_accuracy: 0.9176\n",
            "Epoch 101/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.9167 - val_loss: 0.2917 - val_accuracy: 0.9183\n",
            "Epoch 102/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2995 - accuracy: 0.9171 - val_loss: 0.2914 - val_accuracy: 0.9183\n",
            "Epoch 103/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2992 - accuracy: 0.9171 - val_loss: 0.2912 - val_accuracy: 0.9179\n",
            "Epoch 104/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2989 - accuracy: 0.9173 - val_loss: 0.2910 - val_accuracy: 0.9180\n",
            "Epoch 105/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2986 - accuracy: 0.9172 - val_loss: 0.2908 - val_accuracy: 0.9177\n",
            "Epoch 106/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2983 - accuracy: 0.9173 - val_loss: 0.2905 - val_accuracy: 0.9179\n",
            "Epoch 107/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2979 - accuracy: 0.9173 - val_loss: 0.2902 - val_accuracy: 0.9177\n",
            "Epoch 108/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2977 - accuracy: 0.9173 - val_loss: 0.2900 - val_accuracy: 0.9184\n",
            "Epoch 109/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.9175 - val_loss: 0.2898 - val_accuracy: 0.9181\n",
            "Epoch 110/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2970 - accuracy: 0.9176 - val_loss: 0.2897 - val_accuracy: 0.9183\n",
            "Epoch 111/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2968 - accuracy: 0.9177 - val_loss: 0.2893 - val_accuracy: 0.9181\n",
            "Epoch 112/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2965 - accuracy: 0.9175 - val_loss: 0.2893 - val_accuracy: 0.9181\n",
            "Epoch 113/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2962 - accuracy: 0.9177 - val_loss: 0.2889 - val_accuracy: 0.9183\n",
            "Epoch 114/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2959 - accuracy: 0.9178 - val_loss: 0.2888 - val_accuracy: 0.9191\n",
            "Epoch 115/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2957 - accuracy: 0.9180 - val_loss: 0.2886 - val_accuracy: 0.9188\n",
            "Epoch 116/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2953 - accuracy: 0.9181 - val_loss: 0.2885 - val_accuracy: 0.9184\n",
            "Epoch 117/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2951 - accuracy: 0.9181 - val_loss: 0.2883 - val_accuracy: 0.9186\n",
            "Epoch 118/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2948 - accuracy: 0.9183 - val_loss: 0.2882 - val_accuracy: 0.9187\n",
            "Epoch 119/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2946 - accuracy: 0.9180 - val_loss: 0.2879 - val_accuracy: 0.9186\n",
            "Epoch 120/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2943 - accuracy: 0.9183 - val_loss: 0.2877 - val_accuracy: 0.9183\n",
            "Epoch 121/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2941 - accuracy: 0.9184 - val_loss: 0.2875 - val_accuracy: 0.9190\n",
            "Epoch 122/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2938 - accuracy: 0.9185 - val_loss: 0.2873 - val_accuracy: 0.9189\n",
            "Epoch 123/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2935 - accuracy: 0.9185 - val_loss: 0.2871 - val_accuracy: 0.9192\n",
            "Epoch 124/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.9188 - val_loss: 0.2869 - val_accuracy: 0.9192\n",
            "Epoch 125/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2931 - accuracy: 0.9186 - val_loss: 0.2867 - val_accuracy: 0.9196\n",
            "Epoch 126/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2928 - accuracy: 0.9190 - val_loss: 0.2868 - val_accuracy: 0.9191\n",
            "Epoch 127/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2926 - accuracy: 0.9191 - val_loss: 0.2865 - val_accuracy: 0.9190\n",
            "Epoch 128/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2924 - accuracy: 0.9188 - val_loss: 0.2863 - val_accuracy: 0.9193\n",
            "Epoch 129/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.9190 - val_loss: 0.2862 - val_accuracy: 0.9195\n",
            "Epoch 130/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2919 - accuracy: 0.9191 - val_loss: 0.2860 - val_accuracy: 0.9199\n",
            "Epoch 131/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2916 - accuracy: 0.9191 - val_loss: 0.2858 - val_accuracy: 0.9199\n",
            "Epoch 132/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2914 - accuracy: 0.9191 - val_loss: 0.2855 - val_accuracy: 0.9202\n",
            "Epoch 133/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2912 - accuracy: 0.9190 - val_loss: 0.2854 - val_accuracy: 0.9196\n",
            "Epoch 134/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2910 - accuracy: 0.9192 - val_loss: 0.2852 - val_accuracy: 0.9205\n",
            "Epoch 135/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.9192 - val_loss: 0.2853 - val_accuracy: 0.9196\n",
            "Epoch 136/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2906 - accuracy: 0.9193 - val_loss: 0.2850 - val_accuracy: 0.9199\n",
            "Epoch 137/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2903 - accuracy: 0.9193 - val_loss: 0.2849 - val_accuracy: 0.9198\n",
            "Epoch 138/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2901 - accuracy: 0.9193 - val_loss: 0.2846 - val_accuracy: 0.9200\n",
            "Epoch 139/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2899 - accuracy: 0.9193 - val_loss: 0.2846 - val_accuracy: 0.9197\n",
            "Epoch 140/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2897 - accuracy: 0.9194 - val_loss: 0.2844 - val_accuracy: 0.9202\n",
            "Epoch 141/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2895 - accuracy: 0.9196 - val_loss: 0.2842 - val_accuracy: 0.9204\n",
            "Epoch 142/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2893 - accuracy: 0.9195 - val_loss: 0.2842 - val_accuracy: 0.9200\n",
            "Epoch 143/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.9197 - val_loss: 0.2840 - val_accuracy: 0.9205\n",
            "Epoch 144/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2889 - accuracy: 0.9195 - val_loss: 0.2840 - val_accuracy: 0.9208\n",
            "Epoch 145/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2887 - accuracy: 0.9197 - val_loss: 0.2839 - val_accuracy: 0.9200\n",
            "Epoch 146/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2885 - accuracy: 0.9197 - val_loss: 0.2837 - val_accuracy: 0.9204\n",
            "Epoch 147/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2883 - accuracy: 0.9199 - val_loss: 0.2837 - val_accuracy: 0.9201\n",
            "Epoch 148/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2881 - accuracy: 0.9197 - val_loss: 0.2836 - val_accuracy: 0.9199\n",
            "Epoch 149/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.9197 - val_loss: 0.2834 - val_accuracy: 0.9201\n",
            "Epoch 150/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2877 - accuracy: 0.9200 - val_loss: 0.2832 - val_accuracy: 0.9202\n",
            "Epoch 151/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2876 - accuracy: 0.9199 - val_loss: 0.2831 - val_accuracy: 0.9201\n",
            "Epoch 152/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2874 - accuracy: 0.9200 - val_loss: 0.2829 - val_accuracy: 0.9205\n",
            "Epoch 153/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2872 - accuracy: 0.9202 - val_loss: 0.2829 - val_accuracy: 0.9204\n",
            "Epoch 154/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2870 - accuracy: 0.9200 - val_loss: 0.2827 - val_accuracy: 0.9205\n",
            "Epoch 155/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2868 - accuracy: 0.9200 - val_loss: 0.2826 - val_accuracy: 0.9207\n",
            "Epoch 156/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2866 - accuracy: 0.9203 - val_loss: 0.2825 - val_accuracy: 0.9202\n",
            "Epoch 157/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2865 - accuracy: 0.9201 - val_loss: 0.2824 - val_accuracy: 0.9201\n",
            "Epoch 158/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2863 - accuracy: 0.9202 - val_loss: 0.2822 - val_accuracy: 0.9204\n",
            "Epoch 159/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.9202 - val_loss: 0.2820 - val_accuracy: 0.9210\n",
            "Epoch 160/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2859 - accuracy: 0.9203 - val_loss: 0.2820 - val_accuracy: 0.9207\n",
            "Epoch 161/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2858 - accuracy: 0.9204 - val_loss: 0.2818 - val_accuracy: 0.9207\n",
            "Epoch 162/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.9204 - val_loss: 0.2817 - val_accuracy: 0.9207\n",
            "Epoch 163/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2854 - accuracy: 0.9206 - val_loss: 0.2817 - val_accuracy: 0.9211\n",
            "Epoch 164/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2853 - accuracy: 0.9206 - val_loss: 0.2817 - val_accuracy: 0.9204\n",
            "Epoch 165/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2851 - accuracy: 0.9205 - val_loss: 0.2814 - val_accuracy: 0.9214\n",
            "Epoch 166/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2849 - accuracy: 0.9207 - val_loss: 0.2813 - val_accuracy: 0.9210\n",
            "Epoch 167/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2848 - accuracy: 0.9209 - val_loss: 0.2812 - val_accuracy: 0.9210\n",
            "Epoch 168/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2846 - accuracy: 0.9207 - val_loss: 0.2811 - val_accuracy: 0.9213\n",
            "Epoch 169/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.9208 - val_loss: 0.2811 - val_accuracy: 0.9208\n",
            "Epoch 170/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2843 - accuracy: 0.9209 - val_loss: 0.2810 - val_accuracy: 0.9211\n",
            "Epoch 171/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2841 - accuracy: 0.9209 - val_loss: 0.2810 - val_accuracy: 0.9208\n",
            "Epoch 172/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2840 - accuracy: 0.9209 - val_loss: 0.2809 - val_accuracy: 0.9208\n",
            "Epoch 173/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.9210 - val_loss: 0.2807 - val_accuracy: 0.9212\n",
            "Epoch 174/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.9212 - val_loss: 0.2805 - val_accuracy: 0.9213\n",
            "Epoch 175/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.9211 - val_loss: 0.2805 - val_accuracy: 0.9211\n",
            "Epoch 176/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2834 - accuracy: 0.9214 - val_loss: 0.2803 - val_accuracy: 0.9210\n",
            "Epoch 177/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2832 - accuracy: 0.9211 - val_loss: 0.2802 - val_accuracy: 0.9214\n",
            "Epoch 178/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2831 - accuracy: 0.9212 - val_loss: 0.2802 - val_accuracy: 0.9213\n",
            "Epoch 179/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2830 - accuracy: 0.9213 - val_loss: 0.2801 - val_accuracy: 0.9213\n",
            "Epoch 180/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2828 - accuracy: 0.9216 - val_loss: 0.2799 - val_accuracy: 0.9216\n",
            "Epoch 181/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2826 - accuracy: 0.9214 - val_loss: 0.2800 - val_accuracy: 0.9214\n",
            "Epoch 182/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2825 - accuracy: 0.9216 - val_loss: 0.2797 - val_accuracy: 0.9217\n",
            "Epoch 183/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2824 - accuracy: 0.9216 - val_loss: 0.2799 - val_accuracy: 0.9213\n",
            "Epoch 184/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2822 - accuracy: 0.9216 - val_loss: 0.2797 - val_accuracy: 0.9215\n",
            "Epoch 185/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2821 - accuracy: 0.9216 - val_loss: 0.2797 - val_accuracy: 0.9215\n",
            "Epoch 186/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2819 - accuracy: 0.9216 - val_loss: 0.2793 - val_accuracy: 0.9219\n",
            "Epoch 187/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2818 - accuracy: 0.9217 - val_loss: 0.2794 - val_accuracy: 0.9216\n",
            "Epoch 188/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2817 - accuracy: 0.9217 - val_loss: 0.2795 - val_accuracy: 0.9215\n",
            "Epoch 189/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.9218 - val_loss: 0.2792 - val_accuracy: 0.9215\n",
            "Epoch 190/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2814 - accuracy: 0.9218 - val_loss: 0.2791 - val_accuracy: 0.9216\n",
            "Epoch 191/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2812 - accuracy: 0.9217 - val_loss: 0.2789 - val_accuracy: 0.9217\n",
            "Epoch 192/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.9217 - val_loss: 0.2789 - val_accuracy: 0.9218\n",
            "Epoch 193/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2810 - accuracy: 0.9220 - val_loss: 0.2789 - val_accuracy: 0.9217\n",
            "Epoch 194/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2809 - accuracy: 0.9220 - val_loss: 0.2787 - val_accuracy: 0.9219\n",
            "Epoch 195/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.9221 - val_loss: 0.2788 - val_accuracy: 0.9214\n",
            "Epoch 196/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2806 - accuracy: 0.9218 - val_loss: 0.2787 - val_accuracy: 0.9218\n",
            "Epoch 197/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2805 - accuracy: 0.9221 - val_loss: 0.2785 - val_accuracy: 0.9219\n",
            "Epoch 198/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2803 - accuracy: 0.9222 - val_loss: 0.2784 - val_accuracy: 0.9219\n",
            "Epoch 199/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2802 - accuracy: 0.9222 - val_loss: 0.2784 - val_accuracy: 0.9216\n",
            "Epoch 200/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2801 - accuracy: 0.9223 - val_loss: 0.2784 - val_accuracy: 0.9215\n",
            "Epoch 201/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2800 - accuracy: 0.9222 - val_loss: 0.2783 - val_accuracy: 0.9217\n",
            "Epoch 202/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2798 - accuracy: 0.9222 - val_loss: 0.2781 - val_accuracy: 0.9217\n",
            "Epoch 203/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2797 - accuracy: 0.9223 - val_loss: 0.2782 - val_accuracy: 0.9217\n",
            "Epoch 204/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2796 - accuracy: 0.9225 - val_loss: 0.2782 - val_accuracy: 0.9214\n",
            "Epoch 205/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2795 - accuracy: 0.9224 - val_loss: 0.2780 - val_accuracy: 0.9215\n",
            "Epoch 206/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2794 - accuracy: 0.9223 - val_loss: 0.2780 - val_accuracy: 0.9217\n",
            "Epoch 207/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2792 - accuracy: 0.9223 - val_loss: 0.2779 - val_accuracy: 0.9218\n",
            "Epoch 208/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2778 - val_accuracy: 0.9213\n",
            "Epoch 209/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2790 - accuracy: 0.9226 - val_loss: 0.2777 - val_accuracy: 0.9221\n",
            "Epoch 210/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2789 - accuracy: 0.9224 - val_loss: 0.2776 - val_accuracy: 0.9219\n",
            "Epoch 211/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2787 - accuracy: 0.9226 - val_loss: 0.2778 - val_accuracy: 0.9218\n",
            "Epoch 212/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2787 - accuracy: 0.9227 - val_loss: 0.2775 - val_accuracy: 0.9217\n",
            "Epoch 213/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2785 - accuracy: 0.9227 - val_loss: 0.2775 - val_accuracy: 0.9215\n",
            "Epoch 214/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.9226 - val_loss: 0.2774 - val_accuracy: 0.9217\n",
            "Epoch 215/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2783 - accuracy: 0.9227 - val_loss: 0.2773 - val_accuracy: 0.9216\n",
            "Epoch 216/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2773 - val_accuracy: 0.9220\n",
            "Epoch 217/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2781 - accuracy: 0.9227 - val_loss: 0.2772 - val_accuracy: 0.9220\n",
            "Epoch 218/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9229 - val_loss: 0.2772 - val_accuracy: 0.9218\n",
            "Epoch 219/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2779 - accuracy: 0.9230 - val_loss: 0.2769 - val_accuracy: 0.9223\n",
            "Epoch 220/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2778 - accuracy: 0.9228 - val_loss: 0.2770 - val_accuracy: 0.9224\n",
            "Epoch 221/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2777 - accuracy: 0.9230 - val_loss: 0.2769 - val_accuracy: 0.9218\n",
            "Epoch 222/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.9230 - val_loss: 0.2768 - val_accuracy: 0.9218\n",
            "Epoch 223/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2774 - accuracy: 0.9229 - val_loss: 0.2768 - val_accuracy: 0.9220\n",
            "Epoch 224/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2773 - accuracy: 0.9230 - val_loss: 0.2767 - val_accuracy: 0.9217\n",
            "Epoch 225/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2772 - accuracy: 0.9230 - val_loss: 0.2767 - val_accuracy: 0.9217\n",
            "Epoch 226/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.9231 - val_loss: 0.2766 - val_accuracy: 0.9222\n",
            "Epoch 227/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2770 - accuracy: 0.9233 - val_loss: 0.2766 - val_accuracy: 0.9220\n",
            "Epoch 228/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2769 - accuracy: 0.9232 - val_loss: 0.2765 - val_accuracy: 0.9216\n",
            "Epoch 229/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2768 - accuracy: 0.9232 - val_loss: 0.2764 - val_accuracy: 0.9216\n",
            "Epoch 230/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2767 - accuracy: 0.9234 - val_loss: 0.2762 - val_accuracy: 0.9222\n",
            "Epoch 231/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2766 - accuracy: 0.9233 - val_loss: 0.2763 - val_accuracy: 0.9222\n",
            "Epoch 232/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.9233 - val_loss: 0.2763 - val_accuracy: 0.9220\n",
            "Epoch 233/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2764 - accuracy: 0.9234 - val_loss: 0.2762 - val_accuracy: 0.9219\n",
            "Epoch 234/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2763 - accuracy: 0.9233 - val_loss: 0.2761 - val_accuracy: 0.9218\n",
            "Epoch 235/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2762 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9218\n",
            "Epoch 236/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.9234 - val_loss: 0.2760 - val_accuracy: 0.9218\n",
            "Epoch 237/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2760 - accuracy: 0.9237 - val_loss: 0.2759 - val_accuracy: 0.9221\n",
            "Epoch 238/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2759 - accuracy: 0.9234 - val_loss: 0.2759 - val_accuracy: 0.9223\n",
            "Epoch 239/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2758 - accuracy: 0.9236 - val_loss: 0.2759 - val_accuracy: 0.9219\n",
            "Epoch 240/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2757 - accuracy: 0.9235 - val_loss: 0.2759 - val_accuracy: 0.9219\n",
            "Epoch 241/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2756 - accuracy: 0.9236 - val_loss: 0.2758 - val_accuracy: 0.9219\n",
            "Epoch 242/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.9237 - val_loss: 0.2758 - val_accuracy: 0.9221\n",
            "Epoch 243/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2754 - accuracy: 0.9237 - val_loss: 0.2757 - val_accuracy: 0.9221\n",
            "Epoch 244/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2753 - accuracy: 0.9236 - val_loss: 0.2755 - val_accuracy: 0.9222\n",
            "Epoch 245/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2752 - accuracy: 0.9238 - val_loss: 0.2755 - val_accuracy: 0.9218\n",
            "Epoch 246/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2751 - accuracy: 0.9237 - val_loss: 0.2755 - val_accuracy: 0.9222\n",
            "Epoch 247/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2750 - accuracy: 0.9238 - val_loss: 0.2753 - val_accuracy: 0.9221\n",
            "Epoch 248/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2749 - accuracy: 0.9238 - val_loss: 0.2752 - val_accuracy: 0.9222\n",
            "Epoch 249/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2748 - accuracy: 0.9237 - val_loss: 0.2753 - val_accuracy: 0.9219\n",
            "Epoch 250/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2747 - accuracy: 0.9238 - val_loss: 0.2752 - val_accuracy: 0.9224\n",
            "Epoch 251/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2747 - accuracy: 0.9239 - val_loss: 0.2752 - val_accuracy: 0.9223\n",
            "Epoch 252/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.9239 - val_loss: 0.2751 - val_accuracy: 0.9222\n",
            "Epoch 253/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2745 - accuracy: 0.9240 - val_loss: 0.2751 - val_accuracy: 0.9223\n",
            "Epoch 254/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2744 - accuracy: 0.9241 - val_loss: 0.2752 - val_accuracy: 0.9226\n",
            "Epoch 255/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9238 - val_loss: 0.2750 - val_accuracy: 0.9225\n",
            "Epoch 256/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2742 - accuracy: 0.9241 - val_loss: 0.2750 - val_accuracy: 0.9224\n",
            "Epoch 257/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2741 - accuracy: 0.9239 - val_loss: 0.2749 - val_accuracy: 0.9227\n",
            "Epoch 258/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2740 - accuracy: 0.9241 - val_loss: 0.2747 - val_accuracy: 0.9225\n",
            "Epoch 259/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2739 - accuracy: 0.9240 - val_loss: 0.2747 - val_accuracy: 0.9224\n",
            "Epoch 260/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2738 - accuracy: 0.9240 - val_loss: 0.2748 - val_accuracy: 0.9224\n",
            "Epoch 261/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.9241 - val_loss: 0.2747 - val_accuracy: 0.9223\n",
            "Epoch 262/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2737 - accuracy: 0.9240 - val_loss: 0.2746 - val_accuracy: 0.9227\n",
            "Epoch 263/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2736 - accuracy: 0.9242 - val_loss: 0.2747 - val_accuracy: 0.9222\n",
            "Epoch 264/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2735 - accuracy: 0.9241 - val_loss: 0.2747 - val_accuracy: 0.9225\n",
            "Epoch 265/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2734 - accuracy: 0.9244 - val_loss: 0.2746 - val_accuracy: 0.9224\n",
            "Epoch 266/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2733 - accuracy: 0.9243 - val_loss: 0.2746 - val_accuracy: 0.9224\n",
            "Epoch 267/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.9241 - val_loss: 0.2747 - val_accuracy: 0.9222\n",
            "Epoch 268/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2732 - accuracy: 0.9242 - val_loss: 0.2745 - val_accuracy: 0.9224\n",
            "Epoch 269/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2731 - accuracy: 0.9243 - val_loss: 0.2746 - val_accuracy: 0.9223\n",
            "Epoch 270/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2730 - accuracy: 0.9243 - val_loss: 0.2743 - val_accuracy: 0.9226\n",
            "Epoch 271/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2729 - accuracy: 0.9242 - val_loss: 0.2743 - val_accuracy: 0.9225\n",
            "Epoch 272/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2728 - accuracy: 0.9243 - val_loss: 0.2742 - val_accuracy: 0.9224\n",
            "Epoch 273/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.9244 - val_loss: 0.2743 - val_accuracy: 0.9225\n",
            "Epoch 274/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.9243 - val_loss: 0.2743 - val_accuracy: 0.9227\n",
            "Epoch 275/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.9245 - val_loss: 0.2740 - val_accuracy: 0.9225\n",
            "Epoch 276/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2725 - accuracy: 0.9245 - val_loss: 0.2740 - val_accuracy: 0.9219\n",
            "Epoch 277/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2724 - accuracy: 0.9243 - val_loss: 0.2741 - val_accuracy: 0.9220\n",
            "Epoch 278/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2724 - accuracy: 0.9244 - val_loss: 0.2739 - val_accuracy: 0.9224\n",
            "Epoch 279/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9246 - val_loss: 0.2739 - val_accuracy: 0.9224\n",
            "Epoch 280/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2722 - accuracy: 0.9247 - val_loss: 0.2738 - val_accuracy: 0.9224\n",
            "Epoch 281/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2721 - accuracy: 0.9244 - val_loss: 0.2738 - val_accuracy: 0.9223\n",
            "Epoch 282/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2720 - accuracy: 0.9246 - val_loss: 0.2738 - val_accuracy: 0.9224\n",
            "Epoch 283/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.9247 - val_loss: 0.2737 - val_accuracy: 0.9223\n",
            "Epoch 284/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2719 - accuracy: 0.9246 - val_loss: 0.2737 - val_accuracy: 0.9224\n",
            "Epoch 285/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2718 - accuracy: 0.9246 - val_loss: 0.2736 - val_accuracy: 0.9222\n",
            "Epoch 286/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9247 - val_loss: 0.2736 - val_accuracy: 0.9224\n",
            "Epoch 287/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.9247 - val_loss: 0.2737 - val_accuracy: 0.9226\n",
            "Epoch 288/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2716 - accuracy: 0.9249 - val_loss: 0.2735 - val_accuracy: 0.9226\n",
            "Epoch 289/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2715 - accuracy: 0.9248 - val_loss: 0.2735 - val_accuracy: 0.9223\n",
            "Epoch 290/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2714 - accuracy: 0.9247 - val_loss: 0.2735 - val_accuracy: 0.9224\n",
            "Epoch 291/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9247 - val_loss: 0.2735 - val_accuracy: 0.9225\n",
            "Epoch 292/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2713 - accuracy: 0.9248 - val_loss: 0.2734 - val_accuracy: 0.9224\n",
            "Epoch 293/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.9248 - val_loss: 0.2734 - val_accuracy: 0.9226\n",
            "Epoch 294/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9250 - val_loss: 0.2733 - val_accuracy: 0.9225\n",
            "Epoch 295/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2710 - accuracy: 0.9247 - val_loss: 0.2734 - val_accuracy: 0.9224\n",
            "Epoch 296/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2710 - accuracy: 0.9249 - val_loss: 0.2732 - val_accuracy: 0.9225\n",
            "Epoch 297/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2709 - accuracy: 0.9249 - val_loss: 0.2732 - val_accuracy: 0.9226\n",
            "Epoch 298/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2708 - accuracy: 0.9249 - val_loss: 0.2731 - val_accuracy: 0.9224\n",
            "Epoch 299/300\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.9248 - val_loss: 0.2730 - val_accuracy: 0.9227\n",
            "Epoch 300/300\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2707 - accuracy: 0.9248 - val_loss: 0.2731 - val_accuracy: 0.9229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5yFX4lzWGij"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c3I3jTVRAGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf53b161-e207-4199-8a36-20a7073165a2"
      },
      "source": [
        "#@title Visualize no TensorBoard (EXECUTE-ME!) { display-mode: \"form\" }\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ec48-104-199-196-116.ngrok.io\n"
          ]
        }
      ]
    }
  ]
}